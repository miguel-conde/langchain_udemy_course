{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create chat completion\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/chat/create\n",
    "\n",
    "### Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-BKiWmkfQYGaqYhUkAzL2OpL57Z6f5\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Hello! How can I assist you today?\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1744277424,\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_898ac29719\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 10,\n",
      "    \"prompt_tokens\": 19,\n",
      "    \"total_tokens\": 29,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['choices',\n",
       " 'created',\n",
       " 'id',\n",
       " 'model',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'object',\n",
       " 'service_tier',\n",
       " 'system_fingerprint',\n",
       " 'usage']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(completion) if not x.startswith('_') and not callable(getattr(completion, x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"completion_tokens\": 10,\n",
      "  \"prompt_tokens\": 19,\n",
      "  \"total_tokens\": 29,\n",
      "  \"completion_tokens_details\": {\n",
      "    \"accepted_prediction_tokens\": 0,\n",
      "    \"audio_tokens\": 0,\n",
      "    \"reasoning_tokens\": 0,\n",
      "    \"rejected_prediction_tokens\": 0\n",
      "  },\n",
      "  \"prompt_tokens_details\": {\n",
      "    \"audio_tokens\": 0,\n",
      "    \"cached_tokens\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.usage.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This image features a scenic view of a wooden boardwalk that runs through a lush green field. The sky is blue with some clouds, giving the scene a peaceful and natural atmosphere. There are trees and shrubs in the background.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"completion_tokens\": 46,\n",
      "  \"prompt_tokens\": 1117,\n",
      "  \"total_tokens\": 1163,\n",
      "  \"completion_tokens_details\": {\n",
      "    \"accepted_prediction_tokens\": 0,\n",
      "    \"audio_tokens\": 0,\n",
      "    \"reasoning_tokens\": 0,\n",
      "    \"rejected_prediction_tokens\": 0\n",
      "  },\n",
      "  \"prompt_tokens_details\": {\n",
      "    \"audio_tokens\": 0,\n",
      "    \"cached_tokens\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.usage.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ],\n",
    "  logprobs=True,\n",
    "  top_logprobs=2\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Hello', bytes=[72, 101, 108, 108, 111], logprob=-0.16023093461990356, top_logprobs=[TopLogprob(token='Hello', bytes=[72, 101, 108, 108, 111], logprob=-0.16023093461990356), TopLogprob(token='Hi', bytes=[72, 105], logprob=-1.9102308750152588)]), ChatCompletionTokenLogprob(token='!', bytes=[33], logprob=-4.842555426876061e-06, top_logprobs=[TopLogprob(token='!', bytes=[33], logprob=-4.842555426876061e-06), TopLogprob(token=' there', bytes=[32, 116, 104, 101, 114, 101], logprob=-12.250004768371582)]), ChatCompletionTokenLogprob(token=' How', bytes=[32, 72, 111, 119], logprob=-2.339278580620885e-06, top_logprobs=[TopLogprob(token=' How', bytes=[32, 72, 111, 119], logprob=-2.339278580620885e-06), TopLogprob(token=' What', bytes=[32, 87, 104, 97, 116], logprob=-13.000001907348633)]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-2.816093228830141e-06, top_logprobs=[TopLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-2.816093228830141e-06), TopLogprob(token=' may', bytes=[32, 109, 97, 121], logprob=-12.87500286102295)]), ChatCompletionTokenLogprob(token=' I', bytes=[32, 73], logprob=0.0, top_logprobs=[TopLogprob(token=' I', bytes=[32, 73], logprob=0.0), TopLogprob(token='I', bytes=[73], logprob=-25.125)]), ChatCompletionTokenLogprob(token=' assist', bytes=[32, 97, 115, 115, 105, 115, 116], logprob=-0.0019286326132714748, top_logprobs=[TopLogprob(token=' assist', bytes=[32, 97, 115, 115, 105, 115, 116], logprob=-0.0019286326132714748), TopLogprob(token=' help', bytes=[32, 104, 101, 108, 112], logprob=-6.251928806304932)]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=0.0, top_logprobs=[TopLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=0.0), TopLogprob(token=' today', bytes=[32, 116, 111, 100, 97, 121], logprob=-24.5)]), ChatCompletionTokenLogprob(token=' today', bytes=[32, 116, 111, 100, 97, 121], logprob=0.0, top_logprobs=[TopLogprob(token=' today', bytes=[32, 116, 111, 100, 97, 121], logprob=0.0), TopLogprob(token='?', bytes=[63], logprob=-19.125)]), ChatCompletionTokenLogprob(token='?', bytes=[63], logprob=-7.896309739408025e-07, top_logprobs=[TopLogprob(token='?', bytes=[63], logprob=-7.896309739408025e-07), TopLogprob(token='?\\n', bytes=[63, 10], logprob=-14.125000953674316)])], refusal=None)\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].logprobs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output\n",
    "\n",
    "https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "try:\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
    "        ],\n",
    "        response_format=CalendarEvent,\n",
    "    )\n",
    "\n",
    "    response_message = completion.choices[0].message \n",
    "    event = response_message.parsed\n",
    "\n",
    "    # If the model refuses to respond, you will get a refusal message\n",
    "    if (response_message.refusal):\n",
    "        print(response_message.refusal)\n",
    "    else:\n",
    "        print(response_message.parsed)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n"
     ]
    }
   ],
   "source": [
    "print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=18, prompt_tokens=92, total_tokens=110, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output using `instructor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "\n",
    "# Patch the OpenAI client\n",
    "        \n",
    "client_instructor = instructor.from_openai(client)\n",
    "\n",
    "user_info, completion = client_instructor.chat.completions.create_with_completion(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
    "        ],\n",
    "    response_model=CalendarEvent,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n"
     ]
    }
   ],
   "source": [
    "print(user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-BKiWtu4n88I73uhYSdZh6Na92txps', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dPTIrhiHE8Ut4v7KgkngsQ4J', function=Function(arguments='{\"name\":\"Science Fair\",\"date\":\"Friday\",\"participants\":[\"Alice\",\"Bob\"]}', name='CalendarEvent'), type='function')]))], created=1744277431, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_898ac29719', usage=CompletionUsage(completion_tokens=18, prompt_tokens=94, total_tokens=112, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=18, prompt_tokens=94, total_tokens=112, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "print(completion.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output using `trustcall`\n",
    "\n",
    "NO DISPONIBLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output using `outlines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalendarEvent(name='Science Fair', date='2023-10-06', participants=['Alice', 'Bob'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import outlines.models as models\n",
    "from outlines import generate\n",
    "\n",
    "model = models.openai(\"gpt-4o-mini\")\n",
    "\n",
    "generator = generate.json(model, CalendarEvent)\n",
    "\n",
    "generator(\"Alice and Bob are going to a science fair on Friday.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(model.prompt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['client', 'completion_tokens', 'config', 'prompt_tokens']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(model) if not x.startswith('_') and not callable(getattr(model, x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['format_sequence', 'new_with_replacements', 'stream']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(model) if not x.startswith('_') and callable(getattr(model, x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.AsyncOpenAI at 0x2899570ee70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "chat_completion = await model.client.responses.create(\n",
    "  input=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a famous novels writer in the romanticism age.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a three sentence bedtime story about a unicorn.\"}\n",
    "    ],\n",
    "  model = \"gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_67f7957eaaa88191880a31a101e145b90c1dc1ebe5eec00e', created_at=1744278910.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-2024-08-06', object='response', output=[ResponseOutputMessage(id='msg_67f7957f60408191bd390501fb09824d0c1dc1ebe5eec00e', content=[ResponseOutputText(annotations=[], text='Under the silvery glow of the moon, a gentle unicorn named Celestia roamed the enchanted forest, her mane shimmering with stardust. One night, she discovered a sad, lost child beneath the ancient willow and, with a touch of her horn, filled the child’s heart with warmth and joy. As the dawn broke, Celestia led the child home, leaving a trail of sparkling dreams, forever weaving their destinies with magic and wonder.', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=34, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=94, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=128), user=None, store=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseUsage(input_tokens=34, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=94, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=128)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage = chat_completion.usage\n",
    "usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 94)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.input_tokens, usage.output_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model response\n",
    "\n",
    "+ https://platform.openai.com/docs/api-reference/responses/create\n",
    "+ https://platform.openai.com/docs/guides/responses-vs-chat-completions\n",
    "\n",
    "### Text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_67f63671d57c8191b5a4b4cfaca7a4600e8def67552d7c30', created_at=1744189041.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-2024-08-06', object='response', output=[ResponseOutputMessage(id='msg_67f63672268881919ad1ac39b90543040e8def67552d7c30', content=[ResponseOutputText(annotations=[], text=\"In a moonlit forest where whispering willows swayed, a unicorn with a mane of stardust roamed in search of dreams spun from silver. One night, she met a lonely child who wished for friendship, and with a gentle touch of her horn, turned the child's tears into a cascade of shimmering fireflies. Together, they danced beneath the night sky, their laughter echoing through eternity, leaving traces of magic wherever they wandered.\", type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=34, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=91, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=125), user=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "  model=\"gpt-4o\",\n",
    "  # instructions=\"You are a famous novels writer in the romanticism age.\",\n",
    "  # input=\"Tell me a three sentence bedtime story about a unicorn.\"\n",
    "  # Alternatively, you can use the following format for the input parameter:\n",
    "  input=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a famous novels writer in the romanticism age.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a three sentence bedtime story about a unicorn.\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_67f62f3b29e88191a4b7fdf8664f65f0074a3484430c8165\",\n",
      "  \"created_at\": 1744187195.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_67f62f3be3fc8191a6e903c53b8df5e5074a3484430c8165\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"In a serene glade hidden deep within the ancient Whispering Woods, lived a gentle unicorn named Luna, whose shimmering horn was said to light up with the dreams of the world. One starry night, Luna noticed a curious flicker in the sky, revealing a tiny lost star that had tumbled from its celestial home. With a tender touch of her glowing horn, Luna lifted the star back to the heavens, ensuring that it would continue to twinkle brightly for all dreamers below.\",\n",
      "          \"type\": \"output_text\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null\n",
      "  },\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 18,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 99,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 117\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['created_at',\n",
       " 'error',\n",
       " 'id',\n",
       " 'incomplete_details',\n",
       " 'instructions',\n",
       " 'max_output_tokens',\n",
       " 'metadata',\n",
       " 'model',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'object',\n",
       " 'output',\n",
       " 'output_text',\n",
       " 'parallel_tool_calls',\n",
       " 'previous_response_id',\n",
       " 'reasoning',\n",
       " 'status',\n",
       " 'temperature',\n",
       " 'text',\n",
       " 'tool_choice',\n",
       " 'tools',\n",
       " 'top_p',\n",
       " 'truncation',\n",
       " 'usage',\n",
       " 'user']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(response) if not x.startswith('_') and not callable(getattr(response, x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"input_tokens\": 34,\n",
      "  \"input_tokens_details\": {\n",
      "    \"cached_tokens\": 0\n",
      "  },\n",
      "  \"output_tokens\": 99,\n",
      "  \"output_tokens_details\": {\n",
      "    \"reasoning_tokens\": 0\n",
      "  },\n",
      "  \"total_tokens\": 133\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.usage.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_67f6314acbb48191bce232e9f9b781460d4342fbe4f841c8', created_at=1744187722.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-2024-08-06', object='response', output=[ResponseOutputMessage(id='msg_67f6314c5c288191bf62d60ade3d2c6e0d4342fbe4f841c8', content=[ResponseOutputText(annotations=[], text='The image shows a scenic landscape with a wooden boardwalk path leading through a grassy field. The sky is blue with some clouds, creating a peaceful and open atmosphere.', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=1118, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=34, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=1152), user=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"input_text\", \"text\": \"what is in this image?\" },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"input_tokens\": 1118,\n",
      "  \"input_tokens_details\": {\n",
      "    \"cached_tokens\": 0\n",
      "  },\n",
      "  \"output_tokens\": 34,\n",
      "  \"output_tokens_details\": {\n",
      "    \"reasoning_tokens\": 0\n",
      "  },\n",
      "  \"total_tokens\": 1152\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.usage.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logprobs\n",
    "\n",
    "NO TIENE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output\n",
    "\n",
    "https://platform.openai.com/docs/guides/structured-outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"}\n",
    "        ],\n",
    "        text={\n",
    "            \"format\": {\n",
    "                \"type\": \"json_schema\",\n",
    "                \"name\": \"calendar_event\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"name\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"date\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"participants\": {\n",
    "                            \"type\": \"array\", \n",
    "                            \"items\": {\n",
    "                                \"type\": \"string\"\n",
    "                            }\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"name\", \"date\", \"participants\"],\n",
    "                    \"additionalProperties\": False\n",
    "                },\n",
    "                \"strict\": True\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "except Exception as e:\n",
    "    # handle errors like finish_reason, refusal, content_filter, etc.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"}\n",
    "        ],\n",
    "        response_format=CalendarEvent\n",
    "    )\n",
    "except Exception as e:\n",
    "    # handle errors like finish_reason, refusal, content_filter, etc.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Science Fair', 'date': 'Friday', 'participants': ['Alice', 'Bob']}\n"
     ]
    }
   ],
   "source": [
    "event = json.loads(response.output_text)\n",
    "print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output using `instructor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "\n",
    "# Patch the OpenAI client\n",
    "        \n",
    "client_instructor = instructor.from_openai(client)\n",
    "\n",
    "# user_info, completion = client_instructor.chat.completions.create_with_completion(\n",
    "res = client_instructor.completions.create_with_completion(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
    "        ],\n",
    "    response_model=CalendarEvent,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chat',\n",
       " 'client',\n",
       " 'completions',\n",
       " 'default_model',\n",
       " 'hooks',\n",
       " 'kwargs',\n",
       " 'messages',\n",
       " 'mode',\n",
       " 'provider']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(client_instructor) if not x.startswith('_') and not callable(getattr(client_instructor, x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clear',\n",
       " 'create',\n",
       " 'create_fn',\n",
       " 'create_iterable',\n",
       " 'create_partial',\n",
       " 'create_with_completion',\n",
       " 'handle_kwargs',\n",
       " 'off',\n",
       " 'on']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(client_instructor) if not x.startswith('_') and callable(getattr(client_instructor, x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clear',\n",
       " 'create',\n",
       " 'create_fn',\n",
       " 'create_iterable',\n",
       " 'create_partial',\n",
       " 'create_with_completion',\n",
       " 'handle_kwargs',\n",
       " 'off',\n",
       " 'on']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(client_instructor.chat.completions) if not x.startswith('_') and callable(getattr(client_instructor, x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clear',\n",
       " 'create',\n",
       " 'create_fn',\n",
       " 'create_iterable',\n",
       " 'create_partial',\n",
       " 'create_with_completion',\n",
       " 'handle_kwargs',\n",
       " 'off',\n",
       " 'on']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(client_instructor.completions) if not x.startswith('_') and callable(getattr(client_instructor, x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n"
     ]
    }
   ],
   "source": [
    "print(user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParsedChatCompletion[CalendarEvent](id='chatcmpl-BKLhDHMc715WKiW5HF8qX1RJhLZJR', choices=[ParsedChoice[CalendarEvent](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[CalendarEvent](content='{\"name\":\"Science Fair\",\"date\":\"Friday\",\"participants\":[\"Alice\",\"Bob\"]}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=CalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob'])))], created=1744189659, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_92f14e8683', usage=CompletionUsage(completion_tokens=18, prompt_tokens=92, total_tokens=110, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=18, prompt_tokens=92, total_tokens=110, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "print(completion.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CalendarEvent(name='Science Fair', date='2023-10-20', participants=['Alice', 'Bob']),\n",
       " ChatCompletion(id='chatcmpl-BKlqihHGGBbDij0cg6CcJuo2yMrv7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_4jTmGw7TbGnlW5jy2OUw3aV8', function=Function(arguments='{\"name\":\"Science Fair\",\"date\":\"2023-10-20\",\"participants\":[\"Alice\",\"Bob\"]}', name='CalendarEvent'), type='function')]))], created=1744290192, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_898ac29719', usage=CompletionUsage(completion_tokens=23, prompt_tokens=94, total_tokens=117, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output using `trustcall`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output using `outlines`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlines API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
