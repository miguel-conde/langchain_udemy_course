{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create chat completion\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/chat/create\n",
    "\n",
    "### Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-BKKltMmLBi5Up7OpaYjB12IE3chYM\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Hello! How can I assist you today?\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1744186105,\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_432e014d75\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 10,\n",
      "    \"prompt_tokens\": 19,\n",
      "    \"total_tokens\": 29,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['choices',\n",
       " 'created',\n",
       " 'id',\n",
       " 'model',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'object',\n",
       " 'service_tier',\n",
       " 'system_fingerprint',\n",
       " 'usage']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(completion) if not x.startswith('_') and not callable(getattr(completion, x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"completion_tokens\": 10,\n",
      "  \"prompt_tokens\": 19,\n",
      "  \"total_tokens\": 29,\n",
      "  \"completion_tokens_details\": {\n",
      "    \"accepted_prediction_tokens\": 0,\n",
      "    \"audio_tokens\": 0,\n",
      "    \"reasoning_tokens\": 0,\n",
      "    \"rejected_prediction_tokens\": 0\n",
      "  },\n",
      "  \"prompt_tokens_details\": {\n",
      "    \"audio_tokens\": 0,\n",
      "    \"cached_tokens\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.usage.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The image shows a scenic landscape with a wooden boardwalk path running through a grassy field. The sky is a clear blue with a few scattered clouds. There are trees and shrubs in the background, indicating a natural or park-like setting.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"completion_tokens\": 48,\n",
      "  \"prompt_tokens\": 1117,\n",
      "  \"total_tokens\": 1165,\n",
      "  \"completion_tokens_details\": {\n",
      "    \"accepted_prediction_tokens\": 0,\n",
      "    \"audio_tokens\": 0,\n",
      "    \"reasoning_tokens\": 0,\n",
      "    \"rejected_prediction_tokens\": 0\n",
      "  },\n",
      "  \"prompt_tokens_details\": {\n",
      "    \"audio_tokens\": 0,\n",
      "    \"cached_tokens\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.usage.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[])\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ],\n",
    "  logprobs=True,\n",
    "  top_logprobs=2\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Hello', bytes=[72, 101, 108, 108, 111], logprob=-0.25193455815315247, top_logprobs=[TopLogprob(token='Hello', bytes=[72, 101, 108, 108, 111], logprob=-0.25193455815315247), TopLogprob(token='Hi', bytes=[72, 105], logprob=-1.50193452835083)]), ChatCompletionTokenLogprob(token='!', bytes=[33], logprob=-3.7697225252486533e-06, top_logprobs=[TopLogprob(token='!', bytes=[33], logprob=-3.7697225252486533e-06), TopLogprob(token=' there', bytes=[32, 116, 104, 101, 114, 101], logprob=-12.500003814697266)]), ChatCompletionTokenLogprob(token=' How', bytes=[32, 72, 111, 119], logprob=-1.1472419600977446e-06, top_logprobs=[TopLogprob(token=' How', bytes=[32, 72, 111, 119], logprob=-1.1472419600977446e-06), TopLogprob(token=' What', bytes=[32, 87, 104, 97, 116], logprob=-13.750000953674316)]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-4.246537173457909e-06, top_logprobs=[TopLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-4.246537173457909e-06), TopLogprob(token=' may', bytes=[32, 109, 97, 121], logprob=-12.375003814697266)]), ChatCompletionTokenLogprob(token=' I', bytes=[32, 73], logprob=0.0, top_logprobs=[TopLogprob(token=' I', bytes=[32, 73], logprob=0.0), TopLogprob(token=' assist', bytes=[32, 97, 115, 115, 105, 115, 116], logprob=-25.25)]), ChatCompletionTokenLogprob(token=' assist', bytes=[32, 97, 115, 115, 105, 115, 116], logprob=-0.0028048718813806772, top_logprobs=[TopLogprob(token=' assist', bytes=[32, 97, 115, 115, 105, 115, 116], logprob=-0.0028048718813806772), TopLogprob(token=' help', bytes=[32, 104, 101, 108, 112], logprob=-5.877804756164551)]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=0.0, top_logprobs=[TopLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=0.0), TopLogprob(token=' vocÃª', bytes=[32, 118, 111, 99, 195, 170], logprob=-25.0)]), ChatCompletionTokenLogprob(token=' today', bytes=[32, 116, 111, 100, 97, 121], logprob=0.0, top_logprobs=[TopLogprob(token=' today', bytes=[32, 116, 111, 100, 97, 121], logprob=0.0), TopLogprob(token='?', bytes=[63], logprob=-19.25)]), ChatCompletionTokenLogprob(token='?', bytes=[63], logprob=-1.0280383548888494e-06, top_logprobs=[TopLogprob(token='?', bytes=[63], logprob=-1.0280383548888494e-06), TopLogprob(token='?\\n', bytes=[63, 10], logprob=-14.000000953674316)])], refusal=None)\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].logprobs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output\n",
    "\n",
    "https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "try:\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
    "        ],\n",
    "        response_format=CalendarEvent,\n",
    "    )\n",
    "\n",
    "    response_message = completion.choices[0].message \n",
    "    event = response_message.parsed\n",
    "\n",
    "    # If the model refuses to respond, you will get a refusal message\n",
    "    if (response_message.refusal):\n",
    "        print(response_message.refusal)\n",
    "    else:\n",
    "        print(response_message.parsed)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n"
     ]
    }
   ],
   "source": [
    "print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=18, prompt_tokens=92, total_tokens=110, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output using `instructor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "\n",
    "# Patch the OpenAI client\n",
    "        \n",
    "client_instructor = instructor.from_openai(client)\n",
    "\n",
    "user_info, completion = client_instructor.chat.completions.create_with_completion(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
    "        ],\n",
    "    response_model=CalendarEvent,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n"
     ]
    }
   ],
   "source": [
    "print(user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParsedChatCompletion[CalendarEvent](id='chatcmpl-BKLhDHMc715WKiW5HF8qX1RJhLZJR', choices=[ParsedChoice[CalendarEvent](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[CalendarEvent](content='{\"name\":\"Science Fair\",\"date\":\"Friday\",\"participants\":[\"Alice\",\"Bob\"]}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=CalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob'])))], created=1744189659, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_92f14e8683', usage=CompletionUsage(completion_tokens=18, prompt_tokens=92, total_tokens=110, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=18, prompt_tokens=92, total_tokens=110, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "print(completion.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output using `trustcall`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output using `outlines`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model response\n",
    "\n",
    "+ https://platform.openai.com/docs/api-reference/responses/create\n",
    "+ https://platform.openai.com/docs/guides/responses-vs-chat-completions\n",
    "\n",
    "### Text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_67f63671d57c8191b5a4b4cfaca7a4600e8def67552d7c30', created_at=1744189041.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-2024-08-06', object='response', output=[ResponseOutputMessage(id='msg_67f63672268881919ad1ac39b90543040e8def67552d7c30', content=[ResponseOutputText(annotations=[], text=\"In a moonlit forest where whispering willows swayed, a unicorn with a mane of stardust roamed in search of dreams spun from silver. One night, she met a lonely child who wished for friendship, and with a gentle touch of her horn, turned the child's tears into a cascade of shimmering fireflies. Together, they danced beneath the night sky, their laughter echoing through eternity, leaving traces of magic wherever they wandered.\", type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=34, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=91, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=125), user=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "  model=\"gpt-4o\",\n",
    "  # instructions=\"You are a famous novels writer in the romanticism age.\",\n",
    "  # input=\"Tell me a three sentence bedtime story about a unicorn.\"\n",
    "  # Alternatively, you can use the following format for the input parameter:\n",
    "  input=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a famous novels writer in the romanticism age.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a three sentence bedtime story about a unicorn.\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_67f62f3b29e88191a4b7fdf8664f65f0074a3484430c8165\",\n",
      "  \"created_at\": 1744187195.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_67f62f3be3fc8191a6e903c53b8df5e5074a3484430c8165\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"In a serene glade hidden deep within the ancient Whispering Woods, lived a gentle unicorn named Luna, whose shimmering horn was said to light up with the dreams of the world. One starry night, Luna noticed a curious flicker in the sky, revealing a tiny lost star that had tumbled from its celestial home. With a tender touch of her glowing horn, Luna lifted the star back to the heavens, ensuring that it would continue to twinkle brightly for all dreamers below.\",\n",
      "          \"type\": \"output_text\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null\n",
      "  },\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    }\n",
      "  },\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 18,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 99,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 117\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['created_at',\n",
       " 'error',\n",
       " 'id',\n",
       " 'incomplete_details',\n",
       " 'instructions',\n",
       " 'max_output_tokens',\n",
       " 'metadata',\n",
       " 'model',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'object',\n",
       " 'output',\n",
       " 'output_text',\n",
       " 'parallel_tool_calls',\n",
       " 'previous_response_id',\n",
       " 'reasoning',\n",
       " 'status',\n",
       " 'temperature',\n",
       " 'text',\n",
       " 'tool_choice',\n",
       " 'tools',\n",
       " 'top_p',\n",
       " 'truncation',\n",
       " 'usage',\n",
       " 'user']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(response) if not x.startswith('_') and not callable(getattr(response, x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"input_tokens\": 34,\n",
      "  \"input_tokens_details\": {\n",
      "    \"cached_tokens\": 0\n",
      "  },\n",
      "  \"output_tokens\": 99,\n",
      "  \"output_tokens_details\": {\n",
      "    \"reasoning_tokens\": 0\n",
      "  },\n",
      "  \"total_tokens\": 133\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.usage.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_67f6314acbb48191bce232e9f9b781460d4342fbe4f841c8', created_at=1744187722.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-2024-08-06', object='response', output=[ResponseOutputMessage(id='msg_67f6314c5c288191bf62d60ade3d2c6e0d4342fbe4f841c8', content=[ResponseOutputText(annotations=[], text='The image shows a scenic landscape with a wooden boardwalk path leading through a grassy field. The sky is blue with some clouds, creating a peaceful and open atmosphere.', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=1118, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=34, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=1152), user=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"input_text\", \"text\": \"what is in this image?\" },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"input_tokens\": 1118,\n",
      "  \"input_tokens_details\": {\n",
      "    \"cached_tokens\": 0\n",
      "  },\n",
      "  \"output_tokens\": 34,\n",
      "  \"output_tokens_details\": {\n",
      "    \"reasoning_tokens\": 0\n",
      "  },\n",
      "  \"total_tokens\": 1152\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.usage.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logprobs\n",
    "\n",
    "NO TIENE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output\n",
    "\n",
    "https://platform.openai.com/docs/guides/structured-outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"}\n",
    "        ],\n",
    "        text={\n",
    "            \"format\": {\n",
    "                \"type\": \"json_schema\",\n",
    "                \"name\": \"calendar_event\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"name\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"date\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"participants\": {\n",
    "                            \"type\": \"array\", \n",
    "                            \"items\": {\n",
    "                                \"type\": \"string\"\n",
    "                            }\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"name\", \"date\", \"participants\"],\n",
    "                    \"additionalProperties\": False\n",
    "                },\n",
    "                \"strict\": True\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "except Exception as e:\n",
    "    # handle errors like finish_reason, refusal, content_filter, etc.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"}\n",
    "        ],\n",
    "        response_format=CalendarEvent\n",
    "    )\n",
    "except Exception as e:\n",
    "    # handle errors like finish_reason, refusal, content_filter, etc.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Science Fair', 'date': 'Friday', 'participants': ['Alice', 'Bob']}\n"
     ]
    }
   ],
   "source": [
    "event = json.loads(response.output_text)\n",
    "print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output using `instructor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Responses' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m client_instructor \u001b[38;5;241m=\u001b[39m instructor\u001b[38;5;241m.\u001b[39mfrom_openai(client)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# user_info, completion = client_instructor.chat.completions.create_with_completion(\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mclient_instructor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponses\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-2024-08-06\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExtract the event information.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAlice and Bob are going to a science fair on Friday.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCalendarEvent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Responses' object is not callable"
     ]
    }
   ],
   "source": [
    "import instructor\n",
    "\n",
    "# Patch the OpenAI client\n",
    "        \n",
    "client_instructor = instructor.from_openai(client)\n",
    "\n",
    "# user_info, completion = client_instructor.chat.completions.create_with_completion(\n",
    "res = client_instructor.responses(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
    "        ],\n",
    "    response_model=CalendarEvent,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n"
     ]
    }
   ],
   "source": [
    "print(user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParsedChatCompletion[CalendarEvent](id='chatcmpl-BKLhDHMc715WKiW5HF8qX1RJhLZJR', choices=[ParsedChoice[CalendarEvent](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[CalendarEvent](content='{\"name\":\"Science Fair\",\"date\":\"Friday\",\"participants\":[\"Alice\",\"Bob\"]}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=CalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob'])))], created=1744189659, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_92f14e8683', usage=CompletionUsage(completion_tokens=18, prompt_tokens=92, total_tokens=110, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=18, prompt_tokens=92, total_tokens=110, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "print(completion.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output using `trustcall`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output using `outlines`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlines API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
